{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab4935d",
   "metadata": {},
   "source": [
    "Nama    : San Antonio Limbong\n",
    "\n",
    "Kelas   : 14SI-2\n",
    "\n",
    "NIM     : 12S19033"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5173d6d",
   "metadata": {},
   "source": [
    "# Latihan 1 | Text Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58367ecc",
   "metadata": {},
   "source": [
    "# Latihan 1.1 | Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415822b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, LineTokenizer, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eb1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_tokenize output : ['My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius.', 'Father to a murdered son.', 'Husband to a murdered wife.', 'And I will have my vengeance, in this life or the next.']\n"
     ]
    }
   ],
   "source": [
    "stTokenizer = sent_tokenize\n",
    "print(\"sent_tokenize output :\", stTokenizer(\"My name is Maximus Decimus Meridius, \\\n",
    "commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5aa7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineTokenizer output : ['My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius. ', 'Father to a murdered son. Husband to a murdered wife. ', 'And I will have my vengeance, in this life or the next.']\n"
     ]
    }
   ],
   "source": [
    "lTokenizer = LineTokenizer();\n",
    "print(\"LineTokenizer output :\", lTokenizer.tokenize(\"My name is Maximus Decimus Meridius, \\\n",
    "commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1a73e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer output : ['My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius.', '\\nFather to a murdered son.', 'Husband to a murdered wife.', '\\nAnd I will have my vengeance, in this life or the next.']\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = RegexpTokenizer(pattern=SENTENCE_TOKENS_PATTERN, gaps=True)\n",
    "print(\"RegexpTokenizer output :\", regex_st.tokenize(\"My name is Maximus Decimus Meridius, \\\n",
    "commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b80b80",
   "metadata": {},
   "source": [
    "# Latihan 1.2 | Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af076c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import SpaceTokenizer, RegexpTokenizer, TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44c80f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Tokenizer output: ['By', '11', \"o'clock\", 'on', 'Sunday,', 'the', 'doctor', 'shall', 'open', 'the', 'dispensary.']\n"
     ]
    }
   ],
   "source": [
    "rawText = \"By 11 o'clock on Sunday, the doctor shall open the dispensary.\"\n",
    "sTokenizer = SpaceTokenizer()\n",
    "print(\"Space Tokenizer output:\", sTokenizer.tokenize(rawText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c240fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenizer output : ['By', '11', \"o'clock\", 'on', 'Sunday', ',', 'the', 'doctor', 'shall', 'open', 'the', 'dispensary', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Tokenizer output :\", word_tokenize(rawText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f445ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenizer output : ['By', '11', 'o', 'clock', 'on', 'Sunday', 'the', 'doctor', 'shall', 'open', 'the', 'dispensary']\n"
     ]
    }
   ],
   "source": [
    "TOKEN_PATTERN = r'\\w+'\n",
    "regex_wt = RegexpTokenizer(pattern=TOKEN_PATTERN, gaps=False)\n",
    "print(\"Word Tokenizer output :\", regex_wt.tokenize(rawText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ed3fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Tokenizer output: ['This', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-P', '<3']\n"
     ]
    }
   ],
   "source": [
    "tTokenizer = TweetTokenizer()\n",
    "print(\"Tweet Tokenizer output:\", tTokenizer.tokenize(\"This is a cooool #dummysmiley: :-) :-P <3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0468b9a",
   "metadata": {},
   "source": [
    "# Latihan 2 | Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1fff6",
   "metadata": {},
   "source": [
    "# Latihan 2.1 | Case Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffdeefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case: my name is maximus decimus meridius, \\commander of the armies of the north, general of the felix legions and loyal servant to the true emperor, marcus aurelius. \n",
      "father to a murdered son. husband to a murdered wife. \n",
      "and i will have my vengeance, in this life or the next.\n",
      "Lower case: MY NAME IS MAXIMUS DECIMUS MERIDIUS, \\COMMANDER OF THE ARMIES OF THE NORTH, GENERAL OF THE FELIX LEGIONS AND LOYAL SERVANT TO THE TRUE EMPEROR, MARCUS AURELIUS. \n",
      "FATHER TO A MURDERED SON. HUSBAND TO A MURDERED WIFE. \n",
      "AND I WILL HAVE MY VENGEANCE, IN THIS LIFE OR THE NEXT.\n"
     ]
    }
   ],
   "source": [
    "raw = \"My name is Maximus Decimus Meridius, \\commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"\n",
    "\n",
    "# Lower Case\n",
    "print(\"Lower case:\", raw.lower())\n",
    "\n",
    "# Upper Case\n",
    "print(\"Lower case:\", raw.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab06741",
   "metadata": {},
   "source": [
    "# Latihan 2.2 | Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df3db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3420d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"My name is Maximus Decimus Meridius, \\commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df1828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'maximu', 'decimu', 'meridiu', ',', '\\\\command', 'of', 'the', 'armi', 'of', 'the', 'north', ',', 'gener', 'of', 'the', 'felix', 'legion', 'and', 'loyal', 'servant', 'to', 'the', 'true', 'emperor', ',', 'marcu', 'aureliu', '.', 'father', 'to', 'a', 'murder', 'son', '.', 'husband', 'to', 'a', 'murder', 'wife', '.', 'and', 'i', 'will', 'have', 'my', 'vengeanc', ',', 'in', 'thi', 'life', 'or', 'the', 'next', '.']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a8ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'nam', 'is', 'maxim', 'decim', 'meridi', ',', '\\\\commander', 'of', 'the', 'army', 'of', 'the', 'nor', ',', 'gen', 'of', 'the', 'felix', 'leg', 'and', 'loy', 'serv', 'to', 'the', 'tru', 'emp', ',', 'marc', 'aureli', '.', 'fath', 'to', 'a', 'murd', 'son', '.', 'husband', 'to', 'a', 'murd', 'wif', '.', 'and', 'i', 'wil', 'hav', 'my', 'veng', ',', 'in', 'thi', 'lif', 'or', 'the', 'next', '.']\n"
     ]
    }
   ],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "lStems = [lancaster.stem(t) for t in tokens]\n",
    "print(lStems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d76904",
   "metadata": {},
   "source": [
    "# Latihan 2.3 | Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74ff3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, PorterStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "762b1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"My name is Maximus Decimus Meridius, \\commander of the Armies of the North, General of the Felix Legions and loyal servant to the \\\n",
    "true emperor, Marcus Aurelius. \\nFather to a murdered son. Husband to a murdered wife. \\nAnd \\\n",
    "I will have my vengeance, in this life or the next.\"\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc4226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'maximu', 'decimu', 'meridiu', ',', '\\\\command', 'of', 'the', 'armi', 'of', 'the', 'north', ',', 'gener', 'of', 'the', 'felix', 'legion', 'and', 'loyal', 'servant', 'to', 'the', 'true', 'emperor', ',', 'marcu', 'aureliu', '.', 'father', 'to', 'a', 'murder', 'son', '.', 'husband', 'to', 'a', 'murder', 'wife', '.', 'and', 'i', 'will', 'have', 'my', 'vengeanc', ',', 'in', 'thi', 'life', 'or', 'the', 'next', '.']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "stems = [porter.stem(t) for t in tokens]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c581737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Maximus', 'Decimus', 'Meridius', ',', '\\\\commander', 'of', 'the', 'Armies', 'of', 'the', 'North', ',', 'General', 'of', 'the', 'Felix', 'Legions', 'and', 'loyal', 'servant', 'to', 'the', 'true', 'emperor', ',', 'Marcus', 'Aurelius', '.', 'Father', 'to', 'a', 'murdered', 'son', '.', 'Husband', 'to', 'a', 'murdered', 'wife', '.', 'And', 'I', 'will', 'have', 'my', 'vengeance', ',', 'in', 'this', 'life', 'or', 'the', 'next', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa318eb0",
   "metadata": {},
   "source": [
    "# Latihan 2.3 | Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b25d9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "%matplotlib inline\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28fe78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_words = gutenberg.words('bible-kjv.txt')\n",
    "words_filtered = [e.lower() for e in gb_words if len(e) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af014d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "words = [w for w in words_filtered if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d8fba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(words)\n",
    "fdist2 = nltk.FreqDist(gb_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c51a7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are the most common 10 words in the bag\n",
      "[(',', 70509), ('the', 62103), (':', 43766), ('and', 38847), ('of', 34480), ('.', 26160), ('to', 13396), ('And', 12846), ('that', 12576), ('in', 12331)]\n",
      "Following are the most common 10 words in the bag minus the stopwords\n",
      "[('shall', 9838), ('unto', 8997), ('lord', 7964), ('thou', 5474), ('thy', 4600), ('god', 4472), ('said', 3999), ('thee', 3827), ('upon', 2748), ('man', 2735)]\n"
     ]
    }
   ],
   "source": [
    "print('Following are the most common 10 words in the bag')\n",
    "print(fdist2.most_common(10))\n",
    "print('Following are the most common 10 words in the bag minus the stopwords')\n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad289e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
