{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1d8bbe",
   "metadata": {},
   "source": [
    "Nama  : San Antonio Limbong\n",
    "\n",
    "NIM   : 12S19033"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb23e7",
   "metadata": {},
   "source": [
    "### 1 Persiapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef16300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, math, sys\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import defaultdict\n",
    "import sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb851b",
   "metadata": {},
   "source": [
    "### 2 Part of Speech Tagging\n",
    "#### 2.1 Hidden Markov Model\n",
    "\n",
    "Hidden Markov Model (HMM) adalah algoritma pemodelan urutan generatif (sekuens urutan\n",
    "Naive Bayes). HMM mengharuskan kita untuk mempelajari parameter model, probabilitas\n",
    "transisi dari satu POS tag ke POS tag lainnya dan probabilitas emisi setiap fitur kata yang diberi POS tag, hanya dari kalimat yang diamati. POS tag untuk kata-kata diasumsikan disembunyikan\n",
    "(mis. tidak diberikan). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf98a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \n",
    "    currWord = sentence[index][0]\n",
    "    \n",
    "    if (index > 0):\n",
    "        prevWord = sentence[index - 1][0]\n",
    "    else:\n",
    "        prevWord = '<START>'\n",
    "        \n",
    "    if (index < len(sentence)-1):\n",
    "        nextWord = sentence[index + 1][0]\n",
    "    else:\n",
    "        nextWord = '<END>'\n",
    "    \n",
    "    return {\n",
    "        'word' : currWord,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'curr_is_title': currWord.istitle(),\n",
    "        'prev_is_title': prevWord.istitle(),\n",
    "        'next_is_title': nextWord.istitle(),\n",
    "        'curr_is_lower': currWord.islower(),\n",
    "        'prev_is_lower': prevWord.islower(),\n",
    "        'next_is_lower': nextWord.islower(),\n",
    "        'curr_is_upper': currWord.isupper(),\n",
    "        'prev_is_upper': prevWord.isupper(),\n",
    "        'next_is_upper': nextWord.isupper(),\n",
    "        'curr_is_digit': currWord.isdigit(),\n",
    "        'prev_is_digit': prevWord.isdigit(),\n",
    "        'next_is_digit': nextWord.isdigit(),\n",
    "        'curr_prefix-1': currWord[0],\n",
    "        'curr_prefix-2': currWord[:2],\n",
    "        'curr_prefix-3': currWord[:3],\n",
    "        'curr_suffix-1': currWord[-1],\n",
    "        'curr_suffix-2': currWord[-2:],\n",
    "        'curr_suffix-3': currWord[-3:],\n",
    "        \n",
    "        'prev_prefix-1': prevWord[0],\n",
    "        'prev_prefix-2': prevWord[:2],\n",
    "        'prev_prefix-3': prevWord[:3],\n",
    "        'prev_suffix-1': prevWord[-1],\n",
    "        'prev_suffix-2': prevWord[-2:],\n",
    "        'prev_suffix-3': prevWord[-3:],\n",
    "        \n",
    "        'next_prefix-1': nextWord[0],\n",
    "        'next_prefix-2': nextWord[:2],\n",
    "        'next_prefix-3': nextWord[:3],\n",
    "        'next_suffix-1': nextWord[-1],\n",
    "        'next_suffix-2': nextWord[-2:],\n",
    "        'next_suffix-3': nextWord[-3:],\n",
    "        \n",
    "        'prev_word': prevWord,\n",
    "        'next_word': nextWord,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd4a8d",
   "metadata": {},
   "source": [
    "Blok kode diatas merupakan fungsi Python untuk menghasilkan fitur pada setiap kata (posisi \"indeks\") dalam \"kalimat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d463ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTagProbs(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    tagProbs = np.zeros(numTags)\n",
    "    for sentenceLabels in trainLabels:\n",
    "        for tag in sentenceLabels:\n",
    "            tagProbs[tagsDict[tag]] += 1\n",
    "    tagProbs += 1\n",
    "    return tagProbs / np.sum(tagProbs)\n",
    "\n",
    "def computeStartProbs(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    startProbs = np.zeros(numTags)\n",
    "    for sentenceLabels in trainLabels:\n",
    "        startTag = sentenceLabels[0]\n",
    "        startProbs[tagsDict[startTag]] += 1\n",
    "    startProbs += 1\n",
    "    return startProbs/np.sum(startProbs)\n",
    "\n",
    "def computeTransitionProbabilities(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    transMat = np.zeros(shape=(numTags, numTags))\n",
    "    for sentenceLabels in trainLabels:\n",
    "        for i in range(len(sentenceLabels)-1):\n",
    "            tag1 = tagsDict[sentenceLabels[i]]\n",
    "            tag2 = tagsDict[sentenceLabels[i+1]]\n",
    "            transMat[tag1, tag2] += 1\n",
    "    normalized_transmat = normalize(transMat+1, axis=1, norm='l1')\n",
    "    return normalized_transmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c07a8",
   "metadata": {},
   "source": [
    "Blok kode diatas adalah fungsi untuk menghitung probabilitas setiap POS tag dalam kalimat\n",
    "pelatihan, probabilitas setiap POS tag menjadi tag awal dalam sebuah kalimat dan probabilitas transisi dari satu POS tag ke POS tag lain untuk semua kalimat pelatihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87ec554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmissionProbabilities(trainFeatures, trainLabels, tagsDict):\n",
    "    numTags =  len(tagsDict)\n",
    "    emissionDict = defaultdict(lambda: defaultdict(int))\n",
    "    uniqueKeys = set()\n",
    "    for i in range(len(trainLabels)):\n",
    "        sentenceFeatures = trainFeatures[i]\n",
    "        sentenceLabels = trainLabels[i]\n",
    "        for j in range(len(sentenceLabels)):\n",
    "            tag = sentenceLabels[j]\n",
    "            for key, val in sentenceFeatures[j].items():\n",
    "                transformedKey = str(key) + \"__\" + str(val)\n",
    "                uniqueKeys.add(transformedKey)\n",
    "                emissionDict[tag][transformedKey] += 1\n",
    "    emissionMat = np.zeros(shape=(numTags, len(uniqueKeys)))\n",
    "    featuresDict = {}\n",
    "    for index, key in enumerate(uniqueKeys):\n",
    "        featuresDict[key] = index\n",
    "    for tag in tagsDict.keys():\n",
    "        i = tagsDict[tag]\n",
    "        j = featuresDict[key]\n",
    "        emissionMat[i, j] = emissionDict[tag][key]\n",
    "    normalized_emissionMat = normalize(emissionMat+1, axis=1, norm='l1')\n",
    "    return normalized_emissionMat, featuresDict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f63f0",
   "metadata": {},
   "source": [
    "Blok kode diatas merupakan fungsi untuk menghitung probabilitas emisi, yaitu diberikan\n",
    "POS tag tertentu, tentukan probabilitas kondisional untuk mengamati fitur kata pada tag\n",
    "tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595d73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTags(testFeatures, tagProbs, startProbs, transMat, emissionMat, tagsDict, featuresDict):\n",
    "    numTags = len(tagsDict)\n",
    "    bestTags = []\n",
    "    for sentenceFeatures in testFeatures:\n",
    "        bestTagsSentence = []\n",
    "        lenSentence = len(sentenceFeatures)\n",
    "        probMatrix, tagMatrix = np.zeros(shape = (lenSentence, numTags)),np.zeros(shape=(lenSentence, numTags))\n",
    "        for index in range(lenSentence):\n",
    "            feat = sentenceFeatures[index]\n",
    "            for curr in range(numTags):\n",
    "                emissionProb = 0\n",
    "                for key, val in feat.items():\n",
    "                    transformedKey = str(key) + \"__\" + str(val)\n",
    "                    if transformedKey in featuresDict:\n",
    "                        emissionProb += \\\n",
    "                        math.log(emissionMat[curr, featuresDict[transformedKey]])\n",
    "                    else:\n",
    "                        emissionProb -= math.log(len(featuresDict))\n",
    "                emissionProb += math.log(tagProbs[curr])\n",
    "                maxProb = -sys.float_info.max\n",
    "                maxProbTag = -1\n",
    "                if index == 0:\n",
    "                    probMatrix[index][curr] = \\\n",
    "                    math.log(startProbs[curr]) + emissionProb\n",
    "                    tagMatrix[index][curr] = -1\n",
    "                else:\n",
    "                    for prev in range(numTags):\n",
    "                        tagProb = \\\n",
    "                        math.log(transMat[prev, curr]) + \\\n",
    "                        math.log(probMatrix[index - 1][prev])\n",
    "                        if (tagProb > maxProb):\n",
    "                            maxProb = tagProb\n",
    "                            maxProbTag = prev\n",
    "                    maxProb += emissionProb\n",
    "                    probMatrix[index][curr] = maxProb\n",
    "                    tagMatrix[index][curr] = maxProbTag\n",
    "            const = -np.mean(probMatrix[index])\n",
    "            func = np.vectorize(lambda t: math.exp(t+const))\n",
    "            probMatrix[index] = func(probMatrix[index])\n",
    "            probMatrix = normalize(probMatrix, axis=1, norm='l1')\n",
    "        prevBestTag = None\n",
    "        for index in reversed(range(lenSentence+1)):\n",
    "            if index == lenSentence:\n",
    "                bestTag = probMatrix[index-1].argmax()\n",
    "            else:\n",
    "                bestTag = tagMatrix[index][prevBestTag]\n",
    "            prevBestTag = int(bestTag)\n",
    "            bestTagsSentence.append(prevBestTag)\n",
    "        bestTags.append(list(reversed(bestTagsSentence))[1:])\n",
    "    return bestTags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c926d5b",
   "metadata": {},
   "source": [
    "- 'tagsDict' adalah inverted index untuk POS tag, \n",
    "- 'featuresDict' adalah inverted index untuk fitur kata.\n",
    "- Modul 'predictTags' berfungsi untuk menghitung penugasan POS tag yang paling mungkin untuk urutan kata dalam kalimat menggunakan algoritma Viterbi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5098ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformDatasetSequence(sentences):\n",
    "    wordFeatures, wordLabels = [], []\n",
    "    for sent in sentences:\n",
    "        feats, labels = [], []\n",
    "        for index in range(len(sent)):\n",
    "            feats.append(features(sent, index))\n",
    "            labels.append(sent[index][1])\n",
    "        wordFeatures.append(feats)\n",
    "        wordLabels.append(labels)\n",
    "    return wordFeatures, wordLabels\n",
    "\n",
    "def trainHMM(trainFeatures, trainLabels, tagsDict):\n",
    "    tagProbs = computeTagProbs(trainLabels, tagsDict)\n",
    "    startProbs = computeStartProbs(trainLabels, tagsDict)\n",
    "    transMat = computeTransitionProbabilities(trainLabels, tagsDict)\n",
    "    emissionMat, featuresDict = computeEmissionProbabilities(trainFeatures, trainLabels, tagsDict)\n",
    "    return tagProbs, startProbs, transMat, emissionMat, featuresDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d006ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSeqAccuracy(perdictedTags, actualTags):\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    for i in range(len(predictedTags)):\n",
    "        for j in range(len(predictedTags[i])):\n",
    "            total += 1\n",
    "            if predictedTags[i][j] == actualTags[i][j]:\n",
    "                correct += 1\n",
    "                \n",
    "    return float(correct)/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ee3c8",
   "metadata": {},
   "source": [
    "Blok kode diatas digunakan untuk menghitung akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b670cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "\n",
    "size = int(len(brown_tagged_sents) * 0.7)\n",
    "\n",
    "tags = [tag for (word, tag) in brown.tagged_words()]\n",
    "defaultTag = nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba233978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09594594594594595\n"
     ]
    }
   ],
   "source": [
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "tagsDict = {}\n",
    "for index, tag in enumerate(set(tags)):\n",
    "    tagsDict[tag] = index\n",
    "    \n",
    "trainSeqFeatures, trainSeqLabels = transformDatasetSequence(train_sents)\n",
    "testSeqFeatures, testSeqLabels = transformDatasetSequence(test_sents)\n",
    "\n",
    "tagProbs, startProbs, transMat, emissionMat, featuresDict = \\\n",
    "trainHMM(trainSeqFeatures[:30000], trainSeqLabels[:30000], tagsDict)\n",
    "predictedTags = predictTags(testSeqFeatures[:100], tagProbs,\n",
    "                           startProbs, transMat,\n",
    "                           emissionMat, tagsDict, featuresDict)\n",
    "print(computeSeqAccuracy(predictedTags, \\\n",
    "                        [[tagsDict[tag] for tag in tags]\\\n",
    "                        for tags in testSeqLabels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcff6b6",
   "metadata": {},
   "source": [
    "#### 2.2 Conditional Random Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca9442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCRF(trainFeatures, trainLabels):\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    )\n",
    "    crf.fit(trainFeatures, trainLabels)\n",
    "    return crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0240598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "crf_model = trainCRF(trainSeqFeatures[:5], trainSeqLabels[:5])\n",
    "pred_labels = crf_model.predict(testSeqFeatures)\n",
    "print(computeSeqAccuracy(pred_labels, testSeqLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c43f9c",
   "metadata": {},
   "source": [
    "Definisi parameter dari algoritma ini adalah sebagai berikut:\n",
    "\n",
    "-  'algorithm' mengacu pada teknik optimasi yang digunakan untuk meminimalkan log-linear loss function dan menghitung bobot fitur. 'L-BFGS' sering menjadi pilihan utama untuk sebagian besar model log-linear (dengan jumlah contoh pelatihan yang relatif kecil).\n",
    "-  'c1' mengacu pada istilah konstan untuk istilah regularisasi L1.\n",
    "- 'c2' mengacu pada istilah konstan untuk istilah regularisasi L2.\n",
    "- 'max_iterations' mengacu pada jumlah iterasi dalam algoritma pengoptimalan. Jika algoritma tidak konvergen sebelum 'max_iterations', maka program berhenti mengoptimalkan lebih lanjut.\n",
    "- 'all_possible_transitions' set to 'False' menyiratkan bahwa kita hanya mempelajari bobot untuk transisi yang ada dalam kalimat pelatihan, sedangkan jika diatur ke 'True' akan menghitung bobot untuk semua transisi yang mungkin serta untuk semua transisi yang tidak valid (transisi yang tidak diamati dalam data pelatihan), bobot akan negatif, tetapi bobot dari transisi yang valid akan menyesuaikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e7d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
